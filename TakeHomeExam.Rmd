---
title: "Coding"
author: "Zhaoyan Song"
date: "10/26/2023"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 2
```{r}
#######################################################
## Generate data
gendata <- function(N){
  X = rnorm(N)
  ps = 1/(1+exp(-(X/2-.5)))
  Z = rbinom(N,size=1, prob=ps)
  ## Note this
  # hist(ps)
  mean(Z)
  Y_0 = X + rnorm(N,0,.25)
  Y_1 = 2*X + rnorm(N,0,.25)
  Y = Z*Y_1 + (1-Z)*Y_0
  d = data.frame(Y, Z, X, Y_1, Y_0)
  rownames(d) = 1:N
  d
}
```

## (a) Write down the data generating process in mathematical notation.
There are $N$ units, $i=1,\cdots,N$.

The covariate $X_i\sim N(0,1)$

Propensity score is $Pr(Z_i=1|X=x)=\pi(x)=\frac{1}{1+\exp(-(x/2-.5))}$

Potential outcomes are written as
$Y_i(0)=X_i+\epsilon_i, Y_i(1)=2X_i+\epsilon_i$, and  $\epsilon_i\sim N(0,.5^2)$ are i.i.d.

The observed outcome $Y_i = Z_i Y_i(1)+(1-Z_i)Y_i(0)$.


## (b) Are the ignorabiltiy and overlap assumptions satisfied in this data generating process?

Yes. The ignorabiltiy assumption is satisfied because when conditioning on $X$, the generation of potential outcomes and treatment assignments are completely independent of each other. The overlap assumption is also satisfied because $\exp(\cdot) > 0$ and then $\frac{1}{1+\exp(\cdot)} < 1$ and positive, hence $Pr(Z_i=1|X=x) \in (0,1)$.

## (c) Approximately calculate ATT 
```{r q3c,cache=TRUE}
## Calculate the true ATT approximately by simulating a large sample
set.seed(414)
d= gendata(10000000)
(ATE = mean(d$Y_1 - d$Y_0))

(ATT=mean(d[d$Z==1,'Y_1']-d[d$Z==1,'Y_0']))
```


## (d) Now consider analyzing data from this data generating model with 1:1 matching using the following code. Calculate MSE for N = 100, 200, 500, 1000 and 2000.

```{r q3e, cache=TRUE}
#######################################################
## Code to implement optimal matching
# INSTALL rrelaxiv using instructions in https://errickson.net/rrelaxiv/
#drat::addRepo("rrelaxiv", "https://errickson.net/rrelaxiv")
#install.packages("rrelaxiv")
#install.packages('optmatch')
library(rrelaxiv) # load RELAX-IV solver
library(optmatch)
#library(approxmatch) #load manually
# These files are posted on canvas/midterm/codes
  source('approxmatch/R/covbalance.R')
  source('approxmatch/R/kwaymatching.R')
  source('approxmatch/R/multigrp_dist_struc.R')
  source('approxmatch/R/nrbalancematch.R')
  source('approxmatch/R/tripletmatching.R')
  #######################################################
  #######################################################
simu_data <- function(N, times=100){
  mean_data <- rep(NA, times)
  
  for (j in 1:times){
    ## Iterate from here to (*) 100 times
  ## Simulation for a sample of size N
  d = gendata(N)
  ## Matching
  ## specify the variables to match on
  ## Calculate the distance matrix (Using Mahalanobis dist)
  dist_str <- multigrp_dist_struc(d, 'Z', components=list(mahal='X'), wgts=1)
  ## create the match
  res = kwaymatching(dist_str, 'Z', design=c(1,1),.data=d, verbose=FALSE)
  head(res$match)
  ## Effect estimate
  mean_data[j] <- mean(d[res$match[,1],'Y'] - d[res$match[,2],'Y'])
  ## Calculate the error in estimating ATT
  #} (*)
  }
  MSE <- sum((mean_data-ATT)^2)
   return(MSE) 
}
(res1<-simu_data(100))
(res2<-simu_data(200))
(res3<-simu_data(500))
(res4<-simu_data(1000))
(res5<-simu_data(2000))
  ## Calculate MSE using the calculated errors across iterations



  
```

## (e) Draw a line chart
```{r}
plot(c(100,200,500,1000,2000),c(res1,res2,res3,res4,res5),type='b',col='red',xlab = 'Simulation Numbers', ylab = 'MSE')
```

##(f) Based on the results of the above simulation state a sufficient condition on the propensity score for a 1:1 match giving you a consistent estimator of the ATT.

The propensity score should be close to 1/2 (or not too extreme) in order to get sufficient matches and use almost all the dataset. Hence in every block, i.e., the same covariates, we can have enough overlap between treated and untreated groups.

\newpage

# Question 4

```{r Setup, cache=TRUE}
library(osqp) # library that can solve a convex optimization problem
settings = osqp::osqpSettings(verbose = FALSE,
                                  eps_rel = 1e-8,
                                  eps_abs = 1e-8)


N= 10
T=15
beta0<-beta1<-beta2<-beta3<-beta4<-beta5<-1
T0 = 3 # number of pre-treatment period for
```

## (c) Write a code to generate data

```{r gen_data, cache=TRUE}
gen_Data <- function(T0,N,T=15,beta0=1,beta1=2,beta2=3,beta3=2,beta4=3,beta5=1){
  y = matrix(nrow = N,ncol = T)
  for(i in 1:N) {
  for(t in 1:T) {
    y[i,t] <- beta0+beta1*t+beta2*(i-4)/5+beta3*t*(i-4)/10+rnorm(1,0,.5)
  }
    
  }
  for(t in (T0+1):T) y[1,t] <- y[1,t]+beta4+beta5*t
  return(y)
}
```

## (d) Using the code above write a code to calculate the synthetic control esti- mate.

```{r SC, cache=TRUE}
SC <- function(y,T0){
# treated unit
ytarget = y[1,1:T0]
# set of control units
ycontrol = t(y[-1,1:T0])
# number of controls
n0 = ncol(ycontrol)
## Set up the optimization problem for synthetic control
H = 2*t(ycontrol)%*%ycontrol
D = ycontrol - kronecker(ytarget,t(rep(1,n0)))
delta = diag(t(D)%*%D)
A <- rbind(rep(1, n0), diag(n0))
l <- c(1, numeric(n0))
u <- c(1, rep(1, n0))
w = osqp::solve_osqp(P = H, q = -2*t(ycontrol)%*%ytarget,
A = A, l = l, u = u,
pars = settings)$x
return(w) # returns weight
}
# And estimate at time g will be sum(w*y[,-1,g])
# ATT <- beta4+beta5*(T0+1)

```


## (e)-(f)

```{r}
## calculate standard mean difference
asmd <- function(y,T0,w) {
  ## t=T0
  smd <- rep(NA,T0)
  for (t in 1:T0) {
    num <- y[1,t]-sum(w*y[-1,t])
  yw.bar <- mean(w*y[-1,t])
  den <- sqrt(sum(w*(y[-1,t]-yw.bar)^2))
  smd[t]=num/den
  }
  
  return(mean(smd[t]))
}

set.seed(7934)

```

```{r sim,cache=TRUE}
asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 2
  ATT <- beta4+beta5*(T0+1)
  N <- 10
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 2
  ATT <- beta4+beta5*(T0+1)
  N <- 15
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 2
  ATT <- beta4+beta5*(T0+1)
  N <- 20
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 5
  ATT <- beta4+beta5*(T0+1)
  N <- 10
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 5
  ATT <- beta4+beta5*(T0+1)
  N <- 15
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 5
  ATT <- beta4+beta5*(T0+1)
  N <- 20
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 10
  ATT <- beta4+beta5*(T0+1)
  N <- 10
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 10
  ATT <- beta4+beta5*(T0+1)
  N <- 15
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))

asmd_seq <- rep(NA,100)
bias_seq <- rep(NA,100)
for(sim in 1:100){
  T0 <- 10
  ATT <- beta4+beta5*(T0+1)
  N <- 20
  y <- gen_Data(T0,N)
  w <- SC(y,T0)
  est <- sum(w*y[-1,T0+1])
  asmd_seq[sim] <-  asmd(y,T0,w)
  bias_seq[sim] <- est-ATT
}
cat(paste0('T0=',T0,', N=',N,'\n','Aveage ASMD: ',round(mean(asmd_seq),3), '\n MSE: ',round(mean(bias_seq^2),3),'\n\n'))
```
